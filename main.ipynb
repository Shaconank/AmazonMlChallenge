{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ENTITY VALUE EXTRACTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. SETTING UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import traceback\n",
    "from constants import unit_variations, entity_unit_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logging.getLogger('paddleocr').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATABASE LOCATION\n",
    "dataset_path = \"data/\"\n",
    "\n",
    "train_path = dataset_path + \"train.csv\"\n",
    "test_path = dataset_path + \"test.csv\"\n",
    "sample_test_path = dataset_path + \"sample_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if paths exist\n",
    "import os\n",
    "\n",
    "for path in [train_path, test_path, sample_test_path]:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Missing CSV File: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_indices(s, substring):\n",
    "    pattern = re.compile(re.escape(substring))\n",
    "    matches = pattern.finditer(s)\n",
    "    return [match.start() for match in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_representation(x):\n",
    "    for u in unit_variations:\n",
    "        for r in unit_variations[u]:\n",
    "            if x.lower() == r.lower():\n",
    "                return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clickable_path(path):\n",
    "    if os.path.exists(path):\n",
    "        return f'<a href=\"{path}\" target=\"_blank\">{path}</a>'\n",
    "    else:\n",
    "        return f'Path does not exist: {path}'\n",
    "\n",
    "def display_path(path):\n",
    "    display(HTML(make_clickable_path(path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "\n",
    "from constants import unit_variations, entity_unit_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppocr.utils.logging import get_logger\n",
    "import logging\n",
    "logger = get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = dataset_path + \"special_images/image_2.jpg\"\n",
    "image_entity = \"item_weight\"\n",
    "font_path = \"fonts/latin.ttf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_in):\n",
    "    image_out = cv2.cvtColor(image_in, cv2.COLOR_BGR2RGB)\n",
    "    # image_out = cv2.cvtColor(image_in, cv2.COLOR_BGR2GRAY)\n",
    "    \"\"\"\n",
    "    pre process some tings\n",
    "    \"\"\"\n",
    "\n",
    "    return image_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessed Image\")\n",
    "display_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) TEXT RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ocr(image_array):\n",
    "    return ocr.ocr(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ocr(image_in, result):\n",
    "    boxes = [item[0] for item in result[0]]\n",
    "    texts = [item[1][0] for item in result[0]]\n",
    "    scores = [item[1][1] for item in result[0]]\n",
    "\n",
    "    im_show = draw_ocr(image_in, boxes, texts, scores, font_path=\"fonts/latin.ttf\")\n",
    "    display_image(im_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ocr.ocr(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OCR Output:\")\n",
    "show_ocr(image, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) POST PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(result_in, entity_name):\n",
    "    extracted_measurements = []\n",
    "    extracted_positions = []\n",
    "\n",
    "    if result_in == [None]:\n",
    "        return []\n",
    "\n",
    "    for r in result_in[0]:\n",
    "        location, line = r\n",
    "        text = line[0]\n",
    "\n",
    "        for unit in entity_unit_map[entity_name]:\n",
    "            for rep in unit_variations[unit]:\n",
    "                indices = find_all_indices(text.lower(), rep.lower())\n",
    "\n",
    "                for index in indices:\n",
    "                    if index <= 0:\n",
    "                        continue\n",
    "                    \n",
    "                    next_rep = text[index: index + 2].lower().strip()\n",
    "                    if rep.lower() == 'm' and (next_rep != 'm') and is_valid_representation(next_rep):\n",
    "                        continue\n",
    "\n",
    "                    numbers = [\"\"]\n",
    "                    reformat = text[:index].replace(' ', '')\n",
    "\n",
    "                    i = len(reformat) - 1\n",
    "\n",
    "                    while (i >= 0) and (reformat[i].isnumeric() or reformat[i] in ['-', '.', 'I', ',']):\n",
    "                        char = reformat[i]\n",
    "\n",
    "                        if i == 0 and char == \"I\":\n",
    "                            chat = '1'\n",
    "\n",
    "                        if char.isnumeric() or char == \",\":\n",
    "                            numbers[-1] = char + numbers[-1]\n",
    "                        elif char in ['.']:\n",
    "                            numbers[-1] = '.' + numbers[-1]\n",
    "                        elif char in ['-']:\n",
    "                            numbers.append(\"\")\n",
    "\n",
    "                        i -= 1\n",
    "\n",
    "                    discard_rule = lambda x: len(x.strip().replace('.', '')) > 0\n",
    "                    numbers = filter(discard_rule, numbers)\n",
    "\n",
    "                    numbers = map(lambda x: re.sub(r\"\\.{2,}\", \"\", x), numbers) # *..*\n",
    "                    numbers = map(lambda x: re.sub(r\"\\,{2,}\", \"\", x), numbers) # *,,*\n",
    "                    numbers = map(lambda x: re.sub(r\"\\-{2,}\", \"\", x), numbers) # *--*\n",
    "\n",
    "                    numbers = list(numbers)\n",
    "\n",
    "                    # more than one point\n",
    "                    # keep right most val\n",
    "                    for i, num in enumerate(numbers):\n",
    "                        dot_counts = num.count('.')\n",
    "\n",
    "                        if dot_counts > 1:\n",
    "                            dot_split = num.split('.')\n",
    "                            new_num = '.'.join(dot_split[-2:])\n",
    "                            numbers[i] = new_num\n",
    "\n",
    "                        elif dot_counts == 1 and len(num) >= 2:\n",
    "                            if num[0] == '.':\n",
    "                                numbers[i] = num[1:]\n",
    "                    \n",
    "                    # try to understand europeans\n",
    "                    for i, num in enumerate(numbers):\n",
    "                        num = num.lstrip(',')\n",
    "\n",
    "                        # segregating comma\n",
    "                        pattern = r'(\\d+),(\\d{3,})'\n",
    "                        num = re.sub(pattern, r'\\1\\2', num)\n",
    "\n",
    "                        # point comma\n",
    "                        pattern = r'(\\d+),(\\d{1,2})'\n",
    "                        num = re.sub(pattern, r'\\1.\\2', num)\n",
    "                        \n",
    "                        numbers[i] = num\n",
    "\n",
    "                    numbers = sorted(list(map(lambda x: float(x), numbers)))\n",
    "\n",
    "                    if len(numbers) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    left_most_point = float(\"inf\")\n",
    "                    right_most_point = 0\n",
    "                    bottom_most_point = float(\"inf\")\n",
    "                    top_most_point = 0\n",
    "\n",
    "                    for point in location:\n",
    "                        left_most_point = min(left_most_point, point[0])\n",
    "                        right_most_point = max(right_most_point, point[0])\n",
    "                        bottom_most_point = min(bottom_most_point, point[1])\n",
    "                        top_most_point = max(top_most_point, point[1])\n",
    "\n",
    "                    measurement = f\"[{numbers[0]}, {numbers[1]}] {unit}\" if len(numbers) > 1 else f\"{numbers[0]} {unit}\"\n",
    "                    extracted_measurements.append(measurement)\n",
    "                    extracted_positions.append([measurement, left_most_point, right_most_point, bottom_most_point, top_most_point])\n",
    "\n",
    "    return extracted_measurements, extracted_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract(result, image_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. NAIVE ITERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_output(original_image, ocr_result, image_path, e_name, e_value, p_list, p_value):\n",
    "    display_path(image_path)\n",
    "\n",
    "    if ocr_result != [None]:\n",
    "        show_ocr(original_image, ocr_result)\n",
    "\n",
    "    print(\"entity name:\", e_name)\n",
    "    print(\"expected value:\", e_value)\n",
    "    print(\"predicted list:\", p_list)\n",
    "    print(\"prediction value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(index, row, image_folder_in):\n",
    "    if not row[\"downloaded\"]:\n",
    "        return\n",
    "\n",
    "    image_name = os.path.basename(row[\"image_link\"])\n",
    "    image_path = image_folder_in + image_name\n",
    "\n",
    "    entity_name = row[\"entity_name\"]\n",
    "\n",
    "    if \"entity_value\" in df.columns:\n",
    "        entity_value = row[\"entity_value\"]\n",
    "    else:\n",
    "        entity_value = \"undefined\"\n",
    "\n",
    "    default_prediction = \"1 gram\"\n",
    "    current_index = row[\"index\"] if \"index\" in df.columns else index\n",
    "\n",
    "    predictions = \"Error\"\n",
    "    pred_value = default_prediction\n",
    "\n",
    "    try:\n",
    "        original_image = cv2.imread(image_path)\n",
    "        image_array = preprocess_image(original_image)\n",
    "        ocr_result = get_ocr(image_array)\n",
    "\n",
    "        predictions, positions = extract(ocr_result, entity_name)\n",
    "\n",
    "        # height and width exist in different parts of image\n",
    "        if entity_name == 'height' or entity_name == 'width':\n",
    "            global_leftmost = float('inf')\n",
    "            global_rightmost = 0\n",
    "            global_bottommost = float('inf')\n",
    "            global_topmost = 0\n",
    "            dist_from_wall = []\n",
    "            dist_from_middle = []\n",
    "            \n",
    "            img_height, img_width, _ = image_array.shape\n",
    "\n",
    "            for position in positions:\n",
    "                global_leftmost = min(global_leftmost, position[1])\n",
    "                global_rightmost = max(global_rightmost, position[2])\n",
    "                global_bottommost = min(global_bottommost, position[3])\n",
    "                global_topmost = max(global_topmost, position[4])\n",
    "                \n",
    "                dist_from_wall.append([position[0], min(abs(0 - (position[1] + position[2]) / 2), img_width - (position[1] + position[2]) / 2)])\n",
    "                \n",
    "            middle = (global_leftmost + global_rightmost) / 2\n",
    "\n",
    "            for position in positions:\n",
    "                print(position, img_width, middle)\n",
    "                dist_from_middle.append([position[0], abs(middle - (position[1] + position[2]) / 2)])\n",
    "                \n",
    "            if entity_name == \"height\":\n",
    "                predictions = list(map(lambda x: x[0], sorted(dist_from_wall, key=lambda x: x[1])))\n",
    "                if len(predictions) > 1:\n",
    "                    num_0, unit_0 = predictions[0][:predictions[0].rfind(' ')], predictions[0][predictions[0].rfind(' ') + 1:]\n",
    "                    num_1, unit_1 = predictions[1][:predictions[1].rfind(' ')], predictions[1][predictions[1].rfind(' ') + 1:]\n",
    "                    \n",
    "                    print(predictions)\n",
    "                    try:\n",
    "                        if float(num_1) > float(num_0):\n",
    "                            predictions[0], predictions[1] = predictions[1], predictions[0]\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "            else:\n",
    "                if len(predictions) == 2:\n",
    "                    predictions = list(map(lambda x: x[0], sorted(dist_from_wall, key=lambda x: -x[1])))\n",
    "                else:\n",
    "                    predictions = list(map(lambda x: x[0], sorted(dist_from_middle, key=lambda x: x[1])))\n",
    "\n",
    "        elif entity_name == \"maximum_weight_recommendation\":\n",
    "            try:\n",
    "                predictions = sorted(predictions, key = lambda x: -float(x.split(' ')[0]))\n",
    "            except:\n",
    "                pass\n",
    "                    \n",
    "        # 50mm >> 50m\n",
    "        # if predictions[0].find(\"metre\") != -1 and predictions[1].find(\"metre\") != -1:\n",
    "            # num_0, unit_0 = None, None\n",
    "            # num_1, unit_1 = None, None\n",
    "\n",
    "            # # which one has mm?\n",
    "            # p0, p1 = predictions[0].find(\"millimetre\"), predictions[1].find(\"millimetre\")\n",
    "\n",
    "            # if p0 != p1:\n",
    "            #     if (p0 != -1):\n",
    "            #         num_0, unit_0 = predictions[0][:p0], \"millimetre\"\n",
    "            #         num_1, unit_1 = predictions[1][:p1], \"metre\"\n",
    "            #     elif (p1 != -1):\n",
    "            #         num_0, unit_0 = predictions[1][:p1], \"millimetre\"\n",
    "            #         num_1, unit_1 = predictions[0][:p1], \"metre\"\n",
    "                \n",
    "            #     if num_0 == num_1:\n",
    "            #         predictions[0], predictions[1], = predictions[1], predictions[0]\n",
    "\n",
    "        print(predictions)\n",
    "        pred_value = list(predictions)[0] if len(predictions) > 0 else \"\"\n",
    "\n",
    "        if (entity_value != \"undefined\") and (pred_value.strip() != entity_value.strip()):\n",
    "            raise ValueError(\"Incorrect Answer\")\n",
    "\n",
    "        output_row = {\"index\": current_index, \"image_link\": row[\"image_link\"], \"prediction\": pred_value}\n",
    "\n",
    "    except Exception as e:\n",
    "        output_row = {\"index\": current_index, \"image_link\": row[\"image_link\"], \"prediction\": pred_value}\n",
    "\n",
    "        if PAUSE_ON_ERROR:\n",
    "            print(\"error:\", e)\n",
    "            traceback.print_exc()\n",
    "            debug_output(original_image, ocr_result, image_path, entity_name, entity_value, predictions, pred_value)\n",
    "            choice = input(\"continue [y]: \")\n",
    "            if len(choice.strip()) > 0:\n",
    "                return \"stop\"\n",
    "\n",
    "    if PAUSE_ON_ERROR:\n",
    "        clear_output(wait = True)\n",
    "\n",
    "    return output_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"test\"\n",
    "PAUSE_ON_ERROR = True\n",
    "MULTI_THREADED = True\n",
    "MAX_THREADS = 3\n",
    "\n",
    "if MULTI_THREADED:\n",
    "    PAUSE_ON_ERROR = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = f\"data/{DATASET}_images/\"\n",
    "df_path = f\"data/downloaded_{DATASET}.csv\"\n",
    "output_path = f\"data/{DATASET}_output.csv\"\n",
    "\n",
    "df = pd.read_csv(df_path)\n",
    "output_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[df[\"entity_name\"].isin([\"height\", \"width\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MULTI_THREADED:\n",
    "    with ThreadPoolExecutor(max_workers = MAX_THREADS) as executor:\n",
    "        futures = [executor.submit(process_row, index, row, image_folder) for index, row in df.iterrows()]\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing rows\"):\n",
    "            result = future.result()\n",
    "\n",
    "            if result:\n",
    "                output_array.append(result)\n",
    "\n",
    "            if result == \"stop\":\n",
    "                break\n",
    "\n",
    "else:\n",
    "    for index, row in df.iterrows():\n",
    "        print(f\"{index + 1}/{len(df)}\")\n",
    "        output_row = process_row(index, row, image_folder)\n",
    "\n",
    "        if output_row == \"stop\":\n",
    "            break\n",
    "\n",
    "        output_array.append(output_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(output_array)\n",
    "output_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainforest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
